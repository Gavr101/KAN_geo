{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDmrIUSXGi4S"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8612,
     "status": "ok",
     "timestamp": 1713423753229,
     "user": {
      "displayName": "Артём Гуськов",
      "userId": "11033439813008185974"
     },
     "user_tz": -180
    },
    "id": "4AGhZWzsoWdr",
    "outputId": "06c89db4-de2e-4ff5-b731-273483c28986"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import torch\n",
    "from kan import KAN\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#%load_ext autotime\n",
    "#%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import KAN_es\n",
    "from algos import vector_pred_skl, vector_pred_NN, vector_pred_KAN, multi_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_vld.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_vld.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_vld.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "'''\n",
    "# !Some troubles with *.csv naming!\n",
    "\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_pro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col_names = initial_trn_data_fdfs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(pd.concat([initial_trn_data_fdfs,\n",
    "                         initial_vld_data_fdfs],\n",
    "                        axis=0, sort=False, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaled_trn_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names) \n",
    "scaled_vld_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "scaled_tst_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_udfs),columns=data_col_names)\n",
    "scaled_vld_data_udfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_udfs),columns=data_col_names)\n",
    "scaled_tst_data_udfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_udfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udus = pd.DataFrame(mm_scaler.transform(initial_trn_data_udus),columns=data_col_names)\n",
    "scaled_vld_data_udus = pd.DataFrame(mm_scaler.transform(initial_vld_data_udus),columns=data_col_names)\n",
    "scaled_tst_data_udus = pd.DataFrame(mm_scaler.transform(initial_tst_data_udus),columns=data_col_names)\n",
    "'''\n",
    "trn = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names) \n",
    "vld = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "tst = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for SAD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, :124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, :124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_GMT.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, :31], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, :31], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_G.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, 31:62], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, 31:62], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_M.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, 62:124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, 62:124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_T.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, :124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_GMT.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, :31], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_G.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, 31:62], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_M.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, 62:124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_T.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment №2\n",
    "* Input data: G, M, T, GMT.\n",
    "* Models: Group Method Data Holding, Random Forest, Gradient Boosting, Multi-Layer Perceptron, Kolmogorov-Arnold Network.\n",
    "* Single mode predicting: seperate model per each predicting depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 25\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from gmdh import Ria\n",
    "\n",
    "def skl_regr_wrap(class_model, default_init_kwargs = {}, default_fit_kwargs = {}):\n",
    "    '''\n",
    "    Wrapper for regressor classes with fit, predict methods. Makes regressor compatable with skl cross-validation.\n",
    "    Returns new class.\n",
    "    '''\n",
    "    class MyEstimator(BaseEstimator):\n",
    "        '''\n",
    "        Provides Sci-kit learn compatable Regressor class from class model with fit, predict functions \n",
    "        '''\n",
    "        def __init__(self, *, init_kwargs=default_init_kwargs, fit_kwargs=default_fit_kwargs, random_state=1):\n",
    "            self.init_kwargs = init_kwargs\n",
    "            self.fit_kwargs = fit_kwargs\n",
    "            self.class_model = class_model\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.model = class_model(**self.init_kwargs)\n",
    "            self.model.fit(X=np.array(X), y=np.array(y), **self.fit_kwargs)\n",
    "            self.is_fitted_ = True\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.model.predict(X=X)\n",
    "        \n",
    "        \n",
    "    return MyEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GMDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'GMDH'\n",
    "\n",
    "\n",
    "l_algos_names=['G_GMDH', 'M_GMDH', 'T_GMDH', 'GMT_GMDH']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'RF'\n",
    "\n",
    "\n",
    "l_algos_names=['G_RF', 'M_RF', 'T_RF', 'GMT_RF']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, \n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'GB'\n",
    "\n",
    "\n",
    "l_algos_names=['G_GB', 'M_GB', 'T_GB', 'GMT_GB']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, \n",
    "]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 MLP keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'MLP'\n",
    "\n",
    "\n",
    "l_algos_names=['G_MLP', 'M_MLP', 'T_MLP', 'GMT_MLP']\n",
    "\n",
    "l_algos=[vector_pred_NN, vector_pred_NN, vector_pred_NN, vector_pred_NN,]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'KAN'\n",
    "\n",
    "\n",
    "l_algos_names=['G_KAN', 'M_KAN', 'T_KAN', 'GMT_KAN']\n",
    "\n",
    "l_algos=[vector_pred_KAN, vector_pred_KAN, vector_pred_KAN, vector_pred_KAN]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Extra: MLP from skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'MLP_skl'\n",
    "\n",
    "\n",
    "l_algos_names=['G_MLP_skl', 'M_MLP_skl', 'T_MLP_skl', 'GMT_MLP_skl']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. All experiments in 1 launch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['G_GMDH', 'M_GMDH', 'T_GMDH', 'GMT_GMDH',\n",
    "               'G_RF', 'M_RF', 'T_RF', 'GMT_RF',\n",
    "               'G_GB', 'M_GB', 'T_GB', 'GMT_GB',\n",
    "               'G_MLP', 'M_MLP', 'T_MLP', 'GMT_MLP',\n",
    "               'G_KAN', 'M_KAN', 'T_KAN', 'GMT_KAN']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_NN, vector_pred_NN, vector_pred_NN, vector_pred_NN, \n",
    "         vector_pred_KAN, vector_pred_KAN, vector_pred_KAN, vector_pred_KAN]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4*5)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4*5)]\n",
    "\n",
    "l_kwargs=[{'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          \n",
    "          {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, \n",
    "          \n",
    "          {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, \n",
    "\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          \n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel('full_metrics_2.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel('aggr_metrics_2.xlsx')\n",
    "aggr_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aIL8ByjQk_ZF",
    "QDmrIUSXGi4S",
    "a1xagv6ilIOY",
    "bPtIL2sBHGEr",
    "1F9IQv4404Kw",
    "RL9cZZgsCOF9",
    "SQlkq4mV2jgV",
    "rELgNsuCH-AV",
    "4anop-oMi1bP",
    "u7XdyWo2i9If",
    "q7AyylqGjDds",
    "ASErdt8-koM6",
    "gbynJqCmjDd0",
    "4nKC2GYXjDd3",
    "GTLSE0LqjDd5",
    "LniYe2gKmQU2",
    "JBY35tb-mQVF",
    "LbxePh8_mQVG",
    "sGQL1KcYmQVI",
    "Jv2nOQcDmbx4",
    "mwSMdb-DmbyA",
    "POfYqvJpmbyC",
    "mzulZ0BqmbyE",
    "b2bsNptimnn6",
    "i2kYaUXymnoA",
    "BW6pjojBmnoC",
    "f5ZNCOjImnoE",
    "P-G0m7YHmxjI",
    "STRJXlr5mxjP",
    "YK6-DC1SmxjR",
    "x0mZIr5WmxjT",
    "A_cb4zfCm8e0",
    "LAHjNKyum8e6",
    "r3V68FCLm8e7",
    "5qkzGmPBm8e9",
    "_emLc38km8e_",
    "mBkbRM6um8fB",
    "l2AfJl0Bm8fB",
    "1JvB5Vpnm8fD",
    "VnZLOfnwm8fE",
    "3Smu7Z1fm8fG",
    "ZQdqa0mzm8fG",
    "00bDDaU8m8fI",
    "wo3QxFQPm8fK",
    "LuF8EP2Qm8fM",
    "KXI9Qgpvm8fM",
    "K_rzuvZEm8fP",
    "K9skQHETm8fR",
    "p2s49zpnm8fT",
    "wrtDVW9jm8fT",
    "mtbjCRB1m8fY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
