{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDmrIUSXGi4S"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8612,
     "status": "ok",
     "timestamp": 1713423753229,
     "user": {
      "displayName": "Артём Гуськов",
      "userId": "11033439813008185974"
     },
     "user_tz": -180
    },
    "id": "4AGhZWzsoWdr",
    "outputId": "06c89db4-de2e-4ff5-b731-273483c28986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gavriil\\AppData\\Local\\Temp\\ipykernel_30308\\2711945982.py:28: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import torch\n",
    "from kan import KAN\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#%load_ext autotime\n",
    "#%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import KAN_es\n",
    "from algos import vector_pred_skl, vector_pred_NN, vector_pred_KAN, multi_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_vld.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_vld.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_vld.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "'''\n",
    "# !Some troubles with *.csv naming!\n",
    "\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_pro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col_names = initial_trn_data_fdfs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(pd.concat([initial_trn_data_fdfs,\n",
    "                         initial_vld_data_fdfs],\n",
    "                        axis=0, sort=False, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaled_trn_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names) \n",
    "scaled_vld_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "scaled_tst_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_udfs),columns=data_col_names)\n",
    "scaled_vld_data_udfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_udfs),columns=data_col_names)\n",
    "scaled_tst_data_udfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_udfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udus = pd.DataFrame(mm_scaler.transform(initial_trn_data_udus),columns=data_col_names)\n",
    "scaled_vld_data_udus = pd.DataFrame(mm_scaler.transform(initial_vld_data_udus),columns=data_col_names)\n",
    "scaled_tst_data_udus = pd.DataFrame(mm_scaler.transform(initial_tst_data_udus),columns=data_col_names)\n",
    "'''\n",
    "trn = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names) \n",
    "vld = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "tst = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for SAD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npd.concat([\\npd.concat([ trn.iloc[:, :124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False),\\npd.concat([ vld.iloc[:, :124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)],\\naxis=0, sort=False, ignore_index=False)#.to_csv('trn_GMT.csv')\\n\\npd.concat([\\npd.concat([ trn.iloc[:, :31], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False),\\npd.concat([ vld.iloc[:, :31], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)],\\naxis=0, sort=False, ignore_index=False)#.to_csv('trn_G.csv')\\n\\npd.concat([\\npd.concat([ trn.iloc[:, 31:62], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False),\\npd.concat([ vld.iloc[:, 31:62], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)],\\naxis=0, sort=False, ignore_index=False)#.to_csv('trn_M.csv')\\n\\npd.concat([\\npd.concat([ trn.iloc[:, 62:124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False),\\npd.concat([ vld.iloc[:, 62:124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)],\\naxis=0, sort=False, ignore_index=False)#.to_csv('trn_T.csv')\\n\\npd.concat([ tst.iloc[:, :124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)#.to_csv('tst_GMT.csv')\\n\\npd.concat([ tst.iloc[:, :31], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)#.to_csv('tst_G.csv')\\n\\npd.concat([ tst.iloc[:, 31:62], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)#.to_csv('tst_M.csv')\\n\\npd.concat([ tst.iloc[:, 62:124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\\n          axis=1, sort=False, ignore_index=False)#.to_csv('tst_T.csv')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, :124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, :124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_GMT.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, :31], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, :31], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_G.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, 31:62], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, 31:62], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_M.csv')\n",
    "\n",
    "pd.concat([\n",
    "pd.concat([ trn.iloc[:, 62:124], trn.loc[:,'H1_8'], trn.loc[:,'H2_8'], trn.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False),\n",
    "pd.concat([ vld.iloc[:, 62:124], vld.loc[:,'H1_8'], vld.loc[:,'H2_8'], vld.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)],\n",
    "axis=0, sort=False, ignore_index=False)#.to_csv('trn_T.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, :124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_GMT.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, :31], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_G.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, 31:62], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_M.csv')\n",
    "\n",
    "pd.concat([ tst.iloc[:, 62:124], tst.loc[:,'H1_8'], tst.loc[:,'H2_8'], tst.loc[:,'H3_8'] ],\n",
    "          axis=1, sort=False, ignore_index=False)#.to_csv('tst_T.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment №2\n",
    "* Input data: G, M, T, GMT.\n",
    "* Models: Group Method Data Holding, Random Forest, Gradient Boosting, Multi-Layer Perceptron, Kolmogorov-Arnold Network.\n",
    "* Single mode predicting: seperate model per each predicting depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 25\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from gmdh import Ria\n",
    "\n",
    "def skl_regr_wrap(class_model, default_init_kwargs = {}, default_fit_kwargs = {}):\n",
    "    '''\n",
    "    Wrapper for regressor classes with fit, predict methods. Makes regressor compatable with skl cross-validation.\n",
    "    Returns new class.\n",
    "    '''\n",
    "    class MyEstimator(BaseEstimator):\n",
    "        '''\n",
    "        Provides Sci-kit learn compatable Regressor class from class model with fit, predict functions \n",
    "        '''\n",
    "        def __init__(self, *, init_kwargs=default_init_kwargs, fit_kwargs=default_fit_kwargs, random_state=1):\n",
    "            self.init_kwargs = init_kwargs\n",
    "            self.fit_kwargs = fit_kwargs\n",
    "            self.class_model = class_model\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.model = class_model(**self.init_kwargs)\n",
    "            self.model.fit(X=np.array(X), y=np.array(y), **self.fit_kwargs)\n",
    "            self.is_fitted_ = True\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.model.predict(X=X)\n",
    "        \n",
    "        \n",
    "    return MyEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GMDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing G_GMDH\n",
      "iter: 1\n",
      "<class '__main__.skl_regr_wrap.<locals>.MyEstimator'> fitted with randomseed: 1\n",
      "<class '__main__.skl_regr_wrap.<locals>.MyEstimator'> fitted with randomseed: 1\n",
      "<class '__main__.skl_regr_wrap.<locals>.MyEstimator'> fitted with randomseed: 1\n",
      "iter: 2\n",
      "<class '__main__.skl_regr_wrap.<locals>.MyEstimator'> fitted with randomseed: 2\n",
      "<class '__main__.skl_regr_wrap.<locals>.MyEstimator'> fitted with randomseed: 2\n"
     ]
    }
   ],
   "source": [
    "num_iter=2\n",
    "alg_name_to_save = 'GMDH'\n",
    "\n",
    "\n",
    "l_algos_names=['G_GMDH', 'M_GMDH', 'T_GMDH', 'GMT_GMDH']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing G_RF\n",
      "iter: 1\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> fitted with randomseed: 1\n",
      "iter: 2\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> fitted with randomseed: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     18\u001b[0m l_kwargs\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_model\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestRegressor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_model\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestRegressor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_model\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestRegressor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_model\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestRegressor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, \n\u001b[0;32m     19\u001b[0m           ]\n\u001b[0;32m     21\u001b[0m l_metrics_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     22\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     23\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     24\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m full_df \u001b[38;5;241m=\u001b[39m multi_exp(l_algos_names\u001b[38;5;241m=\u001b[39ml_algos_names,\n\u001b[0;32m     28\u001b[0m                     l_algos\u001b[38;5;241m=\u001b[39ml_algos,\n\u001b[0;32m     29\u001b[0m                     mult_data\u001b[38;5;241m=\u001b[39mmult_data,\n\u001b[0;32m     30\u001b[0m                     l_geophysical_method\u001b[38;5;241m=\u001b[39ml_geophysical_method,\n\u001b[0;32m     31\u001b[0m                     l_output_parameter\u001b[38;5;241m=\u001b[39ml_output_parameter,\n\u001b[0;32m     32\u001b[0m                     l_kwargs\u001b[38;5;241m=\u001b[39ml_kwargs,\n\u001b[0;32m     33\u001b[0m                     l_metrics_names\u001b[38;5;241m=\u001b[39ml_metrics_names,\n\u001b[0;32m     34\u001b[0m                     num_iter\u001b[38;5;241m=\u001b[39mnum_iter)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:716\u001b[0m, in \u001b[0;36mmulti_exp\u001b[1;34m(l_algos_names, l_algos, mult_data, l_geophysical_method, l_output_parameter, l_kwargs, l_metrics_names, num_iter)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m#print(kwargs)\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m     l_metrics \u001b[38;5;241m=\u001b[39m alg(trn, val, test, geophysical_method, output_parameter, randomseed\u001b[38;5;241m=\u001b[39mi, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    717\u001b[0m     res_list\u001b[38;5;241m.\u001b[39mappend([alg_name, i]\u001b[38;5;241m+\u001b[39ml_metrics)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:667\u001b[0m, in \u001b[0;36mvector_pred_skl\u001b[1;34m(trn_data, vld_data, tst_data, geophysical_method, l_output_parameter, randomseed, class_model, model_kwargs, multioutput)\u001b[0m\n\u001b[0;32m    663\u001b[0m _X_tst, _Y_tst \u001b[38;5;241m=\u001b[39m create_XY_data(_tst_data, output_parameter, _geophysical_method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    665\u001b[0m model \u001b[38;5;241m=\u001b[39m class_model(random_state\u001b[38;5;241m=\u001b[39mrandomseed, \n\u001b[0;32m    666\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m--> 667\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(_X_trn_vld, _Y_trn_vld)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fitted with randomseed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandomseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    670\u001b[0m _Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(_X_tst)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m )(\n\u001b[0;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    495\u001b[0m         t,\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    497\u001b[0m         X,\n\u001b[0;32m    498\u001b[0m         y,\n\u001b[0;32m    499\u001b[0m         sample_weight,\n\u001b[0;32m    500\u001b[0m         i,\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'RF'\n",
    "\n",
    "\n",
    "l_algos_names=['G_RF', 'M_RF', 'T_RF', 'GMT_RF']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, \n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'GB'\n",
    "\n",
    "\n",
    "l_algos_names=['G_GB', 'M_GB', 'T_GB', 'GMT_GB']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, \n",
    "]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 MLP keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing G_MLP\n",
      "iter: 1\n",
      "WARNING:tensorflow:From c:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Start train model: ?_G_all_H1_8_rs1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gavriil\\anaconda3\\Lib\\random.py:362: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "c:\\Users\\Gavriil\\anaconda3\\Lib\\random.py:362: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     18\u001b[0m l_kwargs\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m50000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrel_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     19\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m50000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrel_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     20\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m50000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrel_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     21\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m50000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrel_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},]\n\u001b[0;32m     23\u001b[0m l_metrics_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     24\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     25\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     26\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m full_df \u001b[38;5;241m=\u001b[39m multi_exp(l_algos_names\u001b[38;5;241m=\u001b[39ml_algos_names,\n\u001b[0;32m     30\u001b[0m                     l_algos\u001b[38;5;241m=\u001b[39ml_algos,\n\u001b[0;32m     31\u001b[0m                     mult_data\u001b[38;5;241m=\u001b[39mmult_data,\n\u001b[0;32m     32\u001b[0m                     l_geophysical_method\u001b[38;5;241m=\u001b[39ml_geophysical_method,\n\u001b[0;32m     33\u001b[0m                     l_output_parameter\u001b[38;5;241m=\u001b[39ml_output_parameter,\n\u001b[0;32m     34\u001b[0m                     l_kwargs\u001b[38;5;241m=\u001b[39ml_kwargs,\n\u001b[0;32m     35\u001b[0m                     l_metrics_names\u001b[38;5;241m=\u001b[39ml_metrics_names,\n\u001b[0;32m     36\u001b[0m                     num_iter\u001b[38;5;241m=\u001b[39mnum_iter)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:716\u001b[0m, in \u001b[0;36mmulti_exp\u001b[1;34m(l_algos_names, l_algos, mult_data, l_geophysical_method, l_output_parameter, l_kwargs, l_metrics_names, num_iter)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m#print(kwargs)\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m     l_metrics \u001b[38;5;241m=\u001b[39m alg(trn, val, test, geophysical_method, output_parameter, randomseed\u001b[38;5;241m=\u001b[39mi, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    717\u001b[0m     res_list\u001b[38;5;241m.\u001b[39mappend([alg_name, i]\u001b[38;5;241m+\u001b[39ml_metrics)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:244\u001b[0m, in \u001b[0;36mvector_pred_NN\u001b[1;34m(trn_data, vld_data, tst_data, geophysical_method, l_output_parameter, randomseed, model_name_template, learning_rate, momentum, tol, n_iter_no_change, max_epochs, rel_batch_size, hidden_neurons, multioutput)\u001b[0m\n\u001b[0;32m    241\u001b[0m _vector_Y_tst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(_Y_tst\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output_parameter \u001b[38;5;129;01min\u001b[39;00m l_output_parameter:\n\u001b[1;32m--> 244\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_NN(trn_data, vld_data, \n\u001b[0;32m    245\u001b[0m             geophysical_method, output_parameter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, randomseed, \n\u001b[0;32m    246\u001b[0m             hidden_neurons \u001b[38;5;241m=\u001b[39m hidden_neurons,\n\u001b[0;32m    247\u001b[0m             model_name_template\u001b[38;5;241m=\u001b[39mmodel_name_template,\n\u001b[0;32m    248\u001b[0m             learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    249\u001b[0m             tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m    250\u001b[0m             n_iter_no_change\u001b[38;5;241m=\u001b[39mn_iter_no_change,\n\u001b[0;32m    251\u001b[0m             max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m    252\u001b[0m             rel_batch_size\u001b[38;5;241m=\u001b[39mrel_batch_size)\n\u001b[0;32m    255\u001b[0m     _output_parameter \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(output_parameter)\n\u001b[0;32m    256\u001b[0m     _X_tst, _Y_tst \u001b[38;5;241m=\u001b[39m create_XY_data(_tst_data, _output_parameter, _geophysical_method, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:133\u001b[0m, in \u001b[0;36mtrain_NN\u001b[1;34m(trn_data, vld_data, geophysical_method, output_parameter, samples_number, randomseed, model_name_template, learning_rate, tol, n_iter_no_change, max_epochs, rel_batch_size, hidden_neurons)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart train model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, _model_name)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#print(f'{_X_trn.shape=}')\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#print(f'{_Y_trn.shape=}')\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m _history \u001b[38;5;241m=\u001b[39m _model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m_X_trn, y\u001b[38;5;241m=\u001b[39m_Y_trn,\n\u001b[0;32m    134\u001b[0m                       batch_size\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(_X_trn) \u001b[38;5;241m*\u001b[39m rel_batch_size),\n\u001b[0;32m    135\u001b[0m                       epochs\u001b[38;5;241m=\u001b[39mmax_epochs, \u001b[38;5;66;03m#100000,\u001b[39;00m\n\u001b[0;32m    136\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    137\u001b[0m                       callbacks\u001b[38;5;241m=\u001b[39m[_early_stopping],\n\u001b[0;32m    138\u001b[0m                       validation_data\u001b[38;5;241m=\u001b[39m(_X_vld, _Y_vld))\n\u001b[0;32m    140\u001b[0m _n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of epochs for training NN model:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(_n_epochs))\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1855\u001b[0m     )\n\u001b[1;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m   1857\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1858\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   1859\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m   1860\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m   1861\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   1862\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1863\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   1864\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   1865\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   1866\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1867\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1868\u001b[0m )\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n\u001b[0;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2285\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_steps_per_execution:\n\u001b[0;32m   2284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 2285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   2286\u001b[0m     _,\n\u001b[0;32m   2287\u001b[0m     dataset_or_iterator,\n\u001b[0;32m   2288\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:500\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:706\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    702\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 706\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:745\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    742\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    743\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    744\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 745\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3421\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3420\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3421\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   3422\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[0;32m   3423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'MLP'\n",
    "\n",
    "\n",
    "l_algos_names=['G_MLP', 'M_MLP', 'T_MLP', 'GMT_MLP']\n",
    "\n",
    "l_algos=[vector_pred_NN, vector_pred_NN, vector_pred_NN, vector_pred_NN,]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing G_KAN\n",
      "iter: 1\n",
      "1\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trn_ls: 7.60e-02 | vl_ls: 7.66e-02 | e_stop: 0/25 | tst_ls: 7.49e-02 | reg: 1.25e+01 :   1%|      | 3/500 [00:13<36:17,  4.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m\n\u001b[0;32m     18\u001b[0m l_kwargs\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_neurons\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     19\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_neurons\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     20\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_neurons\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     21\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_neurons\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter_no_change\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m     22\u001b[0m           ]\n\u001b[0;32m     24\u001b[0m l_metrics_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     25\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     26\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     27\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H1_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H2_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_H3_8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 30\u001b[0m full_df \u001b[38;5;241m=\u001b[39m multi_exp(l_algos_names\u001b[38;5;241m=\u001b[39ml_algos_names,\n\u001b[0;32m     31\u001b[0m                     l_algos\u001b[38;5;241m=\u001b[39ml_algos,\n\u001b[0;32m     32\u001b[0m                     mult_data\u001b[38;5;241m=\u001b[39mmult_data,\n\u001b[0;32m     33\u001b[0m                     l_geophysical_method\u001b[38;5;241m=\u001b[39ml_geophysical_method,\n\u001b[0;32m     34\u001b[0m                     l_output_parameter\u001b[38;5;241m=\u001b[39ml_output_parameter,\n\u001b[0;32m     35\u001b[0m                     l_kwargs\u001b[38;5;241m=\u001b[39ml_kwargs,\n\u001b[0;32m     36\u001b[0m                     l_metrics_names\u001b[38;5;241m=\u001b[39ml_metrics_names,\n\u001b[0;32m     37\u001b[0m                     num_iter\u001b[38;5;241m=\u001b[39mnum_iter)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:716\u001b[0m, in \u001b[0;36mmulti_exp\u001b[1;34m(l_algos_names, l_algos, mult_data, l_geophysical_method, l_output_parameter, l_kwargs, l_metrics_names, num_iter)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m#print(kwargs)\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m     l_metrics \u001b[38;5;241m=\u001b[39m alg(trn, val, test, geophysical_method, output_parameter, randomseed\u001b[38;5;241m=\u001b[39mi, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    717\u001b[0m     res_list\u001b[38;5;241m.\u001b[39mappend([alg_name, i]\u001b[38;5;241m+\u001b[39ml_metrics)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:519\u001b[0m, in \u001b[0;36mvector_pred_KAN\u001b[1;34m(trn_data, vld_data, tst_data, geophysical_method, l_output_parameter, randomseed, K, hidden_neurons, learning_rate, tol, n_iter_no_change, max_epochs, lamb, multioutput)\u001b[0m\n\u001b[0;32m    515\u001b[0m dataset_3 \u001b[38;5;241m=\u001b[39m get_KAN_dataset(trn_data, vld_data, tst_data,\n\u001b[0;32m    516\u001b[0m                 geophysical_method, output_parameter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28mprint\u001b[39m(hidden_neurons)\n\u001b[1;32m--> 519\u001b[0m model \u001b[38;5;241m=\u001b[39m train_KAN(dataset_3,\n\u001b[0;32m    520\u001b[0m                   RS\u001b[38;5;241m=\u001b[39mrandomseed,\n\u001b[0;32m    521\u001b[0m                   K\u001b[38;5;241m=\u001b[39mK,\n\u001b[0;32m    522\u001b[0m                   hidden_neurons\u001b[38;5;241m=\u001b[39mhidden_neurons,\n\u001b[0;32m    523\u001b[0m                   learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    524\u001b[0m                   tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m    525\u001b[0m                   n_iter_no_change\u001b[38;5;241m=\u001b[39mn_iter_no_change,\n\u001b[0;32m    526\u001b[0m                   max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m    527\u001b[0m                   lamb\u001b[38;5;241m=\u001b[39mlamb)\n\u001b[0;32m    529\u001b[0m _Y_tst \u001b[38;5;241m=\u001b[39m dataset_3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    530\u001b[0m _Y_pred \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mforward(dataset_3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\algos.py:481\u001b[0m, in \u001b[0;36mtrain_KAN\u001b[1;34m(dataset_3, RS, K, hidden_neurons, learning_rate, tol, n_iter_no_change, max_epochs, lamb)\u001b[0m\n\u001b[0;32m    477\u001b[0m OUTPUT_SHAPE \u001b[38;5;241m=\u001b[39m dataset_3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    479\u001b[0m model \u001b[38;5;241m=\u001b[39m KAN_es(width\u001b[38;5;241m=\u001b[39m[INPUT_SHAPE, hidden_neurons, OUTPUT_SHAPE], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, k\u001b[38;5;241m=\u001b[39mK, seed\u001b[38;5;241m=\u001b[39mRS)\n\u001b[1;32m--> 481\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_es(dataset_3,\n\u001b[0;32m    482\u001b[0m                       tol\u001b[38;5;241m=\u001b[39mtol, \u001b[38;5;66;03m#0.0001\u001b[39;00m\n\u001b[0;32m    483\u001b[0m                       n_iter_no_change\u001b[38;5;241m=\u001b[39mn_iter_no_change,\n\u001b[0;32m    484\u001b[0m                       opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39mmax_epochs, \n\u001b[0;32m    485\u001b[0m                       lamb\u001b[38;5;241m=\u001b[39mlamb,\n\u001b[0;32m    486\u001b[0m                       lamb_l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    487\u001b[0m                       lamb_entropy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    488\u001b[0m                       lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, result\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\tools.py:258\u001b[0m, in \u001b[0;36mKAN_es.train_es\u001b[1;34m(self, dataset, tol, n_iter_no_change, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, sglr_avoid, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_grid_from_samples(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 258\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    261\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\LBFGS.py:443\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[1;32m--> 443\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m _strong_wolfe(\n\u001b[0;32m    444\u001b[0m         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    446\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\LBFGS.py:100\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[0;32m     98\u001b[0m g_prev \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m     99\u001b[0m gtd_prev \u001b[38;5;241m=\u001b[39m gtd_new\n\u001b[1;32m--> 100\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m obj_func(x, t, d)\n\u001b[0;32m    101\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    102\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\LBFGS.py:442\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[1;34m(x, t, d)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\LBFGS.py:291\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[1;34m(self, closure, x, t, d)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m--> 291\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(closure())\n\u001b[0;32m    292\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\VS_projects\\ARCHIVE_git\\KAN_geo\\tools.py:232\u001b[0m, in \u001b[0;36mKAN_es.train_es.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m train_loss, reg_\n\u001b[0;32m    231\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 232\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sglr_avoid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     id_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39misnan(torch\u001b[38;5;241m.\u001b[39msum(pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\MultKAN.py:785\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[1;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 785\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fun[l](x)\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m#print(preacts, postacts_numerical, postspline)\u001b[39;00m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\KANLayer.py:157\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    154\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mexpand(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    156\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x) \u001b[38;5;66;03m# (batch, in_dim)\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m y \u001b[38;5;241m=\u001b[39m coef2curve(x_eval\u001b[38;5;241m=\u001b[39mx, grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid, coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[0;32m    159\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    161\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m base[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\spline.py:75\u001b[0m, in \u001b[0;36mcoef2curve\u001b[1;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoef2curve\u001b[39m(x_eval, grid, coef, k, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    converting B-spline coefficients to B-spline curves. Evaluate x on B-spline curves (summing up B_batch results over B-spline basis).\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     b_splines \u001b[38;5;241m=\u001b[39m B_batch(x_eval, grid, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m     76\u001b[0m     y_eval \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijk,jlk->ijl\u001b[39m\u001b[38;5;124m'\u001b[39m, b_splines, coef\u001b[38;5;241m.\u001b[39mto(b_splines\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
      "File \u001b[1;32mc:\\Users\\Gavriil\\anaconda3\\Lib\\site-packages\\kan\\spline.py:46\u001b[0m, in \u001b[0;36mB_batch\u001b[1;34m(x, grid, k, extend, device)\u001b[0m\n\u001b[0;32m     42\u001b[0m     value \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]) \u001b[38;5;241m/\u001b[39m (grid[:, :, k:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m     43\u001b[0m                 grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m x) \u001b[38;5;241m/\u001b[39m (grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m grid[:, :, \u001b[38;5;241m1\u001b[39m:(\u001b[38;5;241m-\u001b[39mk)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# in case grid is degenerate\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(value)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'KAN'\n",
    "\n",
    "\n",
    "l_algos_names=['G_KAN', 'M_KAN', 'T_KAN', 'GMT_KAN']\n",
    "\n",
    "l_algos=[vector_pred_KAN, vector_pred_KAN, vector_pred_KAN, vector_pred_KAN]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Extra: MLP from skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing G_MLP_skl\n",
      "iter: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "-------\n",
      "--- Processing M_MLP_skl\n",
      "iter: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "-------\n",
      "--- Processing T_MLP_skl\n",
      "iter: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "-------\n",
      "--- Processing GMT_MLP_skl\n",
      "iter: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> fitted with randomseed: 1\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "num_iter=NUM_ITER\n",
    "alg_name_to_save = 'MLP_skl'\n",
    "\n",
    "\n",
    "l_algos_names=['G_MLP_skl', 'M_MLP_skl', 'T_MLP_skl', 'GMT_MLP_skl']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4)]\n",
    "\n",
    "l_kwargs=[{'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "\n",
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>iter</th>\n",
       "      <th>rmse_H1_8</th>\n",
       "      <th>rmse_H2_8</th>\n",
       "      <th>rmse_H3_8</th>\n",
       "      <th>mae_H1_8</th>\n",
       "      <th>mae_H2_8</th>\n",
       "      <th>mae_H3_8</th>\n",
       "      <th>mape_H1_8</th>\n",
       "      <th>mape_H2_8</th>\n",
       "      <th>mape_H3_8</th>\n",
       "      <th>r2_H1_8</th>\n",
       "      <th>r2_H2_8</th>\n",
       "      <th>r2_H3_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G_MLP_skl</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07523</td>\n",
       "      <td>0.29712</td>\n",
       "      <td>0.30559</td>\n",
       "      <td>0.06191</td>\n",
       "      <td>0.25516</td>\n",
       "      <td>0.24325</td>\n",
       "      <td>6.903446e+12</td>\n",
       "      <td>2.077278e+14</td>\n",
       "      <td>3.429685e+14</td>\n",
       "      <td>0.91926</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.23974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_MLP_skl</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09124</td>\n",
       "      <td>0.15838</td>\n",
       "      <td>0.29361</td>\n",
       "      <td>0.07238</td>\n",
       "      <td>0.12852</td>\n",
       "      <td>0.23412</td>\n",
       "      <td>8.882545e+12</td>\n",
       "      <td>6.939737e+13</td>\n",
       "      <td>3.031247e+14</td>\n",
       "      <td>0.88126</td>\n",
       "      <td>0.74475</td>\n",
       "      <td>0.29815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T_MLP_skl</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10449</td>\n",
       "      <td>0.12132</td>\n",
       "      <td>0.28352</td>\n",
       "      <td>0.08315</td>\n",
       "      <td>0.09659</td>\n",
       "      <td>0.22899</td>\n",
       "      <td>8.877593e+12</td>\n",
       "      <td>4.163186e+13</td>\n",
       "      <td>2.831321e+14</td>\n",
       "      <td>0.84428</td>\n",
       "      <td>0.85022</td>\n",
       "      <td>0.34557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMT_MLP_skl</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00931</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>0.17314</td>\n",
       "      <td>0.00719</td>\n",
       "      <td>0.04740</td>\n",
       "      <td>0.13713</td>\n",
       "      <td>5.623794e+11</td>\n",
       "      <td>2.087050e+13</td>\n",
       "      <td>1.420719e+14</td>\n",
       "      <td>0.99876</td>\n",
       "      <td>0.96418</td>\n",
       "      <td>0.75594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alg_name  iter  rmse_H1_8  rmse_H2_8  rmse_H3_8  mae_H1_8  mae_H2_8  \\\n",
       "0    G_MLP_skl     1    0.07523    0.29712    0.30559   0.06191   0.25516   \n",
       "1    M_MLP_skl     1    0.09124    0.15838    0.29361   0.07238   0.12852   \n",
       "2    T_MLP_skl     1    0.10449    0.12132    0.28352   0.08315   0.09659   \n",
       "3  GMT_MLP_skl     1    0.00931    0.05933    0.17314   0.00719   0.04740   \n",
       "\n",
       "   mae_H3_8     mape_H1_8     mape_H2_8     mape_H3_8  r2_H1_8  r2_H2_8  \\\n",
       "0   0.24325  6.903446e+12  2.077278e+14  3.429685e+14  0.91926  0.10160   \n",
       "1   0.23412  8.882545e+12  6.939737e+13  3.031247e+14  0.88126  0.74475   \n",
       "2   0.22899  8.877593e+12  4.163186e+13  2.831321e+14  0.84428  0.85022   \n",
       "3   0.13713  5.623794e+11  2.087050e+13  1.420719e+14  0.99876  0.96418   \n",
       "\n",
       "   r2_H3_8  \n",
       "0  0.23974  \n",
       "1  0.29815  \n",
       "2  0.34557  \n",
       "3  0.75594  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel(f'full_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel(f'aggr_metrics_2_{alg_name_to_save}.xlsx')\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. All experiments in 1 launch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['G_GMDH', 'M_GMDH', 'T_GMDH', 'GMT_GMDH',\n",
    "               'G_RF', 'M_RF', 'T_RF', 'GMT_RF',\n",
    "               'G_GB', 'M_GB', 'T_GB', 'GMT_GB',\n",
    "               'G_MLP', 'M_MLP', 'T_MLP', 'GMT_MLP',\n",
    "               'G_KAN', 'M_KAN', 'T_KAN', 'GMT_KAN']\n",
    "\n",
    "l_algos=[vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_skl, vector_pred_skl, vector_pred_skl, vector_pred_skl, \n",
    "         vector_pred_NN, vector_pred_NN, vector_pred_NN, vector_pred_NN, \n",
    "         vector_pred_KAN, vector_pred_KAN, vector_pred_KAN, vector_pred_KAN]\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(4*5)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT',\n",
    "                        'G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(4*5)]\n",
    "\n",
    "l_kwargs=[{'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True}, \n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          {'class_model': skl_regr_wrap(class_model=Ria), 'model_kwargs': dict(fit_kwargs = dict(k_best=15, p_average=1)), 'multioutput': True},\n",
    "          \n",
    "          {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, {'class_model': RandomForestRegressor, 'multioutput': True}, \n",
    "          \n",
    "          {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, {'class_model': GradientBoostingRegressor, 'multioutput': True}, \n",
    "\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          \n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_excel('full_metrics_2.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df = full_df.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df.to_excel('aggr_metrics_2.xlsx')\n",
    "aggr_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aIL8ByjQk_ZF",
    "QDmrIUSXGi4S",
    "a1xagv6ilIOY",
    "bPtIL2sBHGEr",
    "1F9IQv4404Kw",
    "RL9cZZgsCOF9",
    "SQlkq4mV2jgV",
    "rELgNsuCH-AV",
    "4anop-oMi1bP",
    "u7XdyWo2i9If",
    "q7AyylqGjDds",
    "ASErdt8-koM6",
    "gbynJqCmjDd0",
    "4nKC2GYXjDd3",
    "GTLSE0LqjDd5",
    "LniYe2gKmQU2",
    "JBY35tb-mQVF",
    "LbxePh8_mQVG",
    "sGQL1KcYmQVI",
    "Jv2nOQcDmbx4",
    "mwSMdb-DmbyA",
    "POfYqvJpmbyC",
    "mzulZ0BqmbyE",
    "b2bsNptimnn6",
    "i2kYaUXymnoA",
    "BW6pjojBmnoC",
    "f5ZNCOjImnoE",
    "P-G0m7YHmxjI",
    "STRJXlr5mxjP",
    "YK6-DC1SmxjR",
    "x0mZIr5WmxjT",
    "A_cb4zfCm8e0",
    "LAHjNKyum8e6",
    "r3V68FCLm8e7",
    "5qkzGmPBm8e9",
    "_emLc38km8e_",
    "mBkbRM6um8fB",
    "l2AfJl0Bm8fB",
    "1JvB5Vpnm8fD",
    "VnZLOfnwm8fE",
    "3Smu7Z1fm8fG",
    "ZQdqa0mzm8fG",
    "00bDDaU8m8fI",
    "wo3QxFQPm8fK",
    "LuF8EP2Qm8fM",
    "KXI9Qgpvm8fM",
    "K_rzuvZEm8fP",
    "K9skQHETm8fR",
    "p2s49zpnm8fT",
    "wrtDVW9jm8fT",
    "mtbjCRB1m8fY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
