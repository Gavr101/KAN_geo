{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDmrIUSXGi4S"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8612,
     "status": "ok",
     "timestamp": 1713423753229,
     "user": {
      "displayName": "Артём Гуськов",
      "userId": "11033439813008185974"
     },
     "user_tz": -180
    },
    "id": "4AGhZWzsoWdr",
    "outputId": "06c89db4-de2e-4ff5-b731-273483c28986"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import torch\n",
    "from kan import KAN\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import KAN_es\n",
    "from algos import create_XY_data, vector_pred_NN, vector_pred_KAN, multi_exp, alg_keras_mlp_3_output, vector_pred_KAN_3_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_vld.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_vld.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_vld.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "'''\n",
    "# !Some troubles with *.csv naming!\n",
    "\n",
    "initial_trn_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_trn.csv\")\n",
    "initial_vld_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_tst.csv\")\n",
    "initial_tst_data_fdfs = pd.read_csv(\"datasets_mtgm\\mtgm_fdfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_trn.csv\")\n",
    "initial_vld_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_tst.csv\")\n",
    "initial_tst_data_udfs = pd.read_csv(\"datasets_mtgm\\mtgm_udfs_10k_pro.csv\")\n",
    "\n",
    "initial_trn_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_trn.csv\")\n",
    "initial_vld_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_tst.csv\")\n",
    "initial_tst_data_udus = pd.read_csv(\"datasets_mtgm\\mtgm_udus_10k_pro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col_names = initial_trn_data_fdfs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(pd.concat([initial_trn_data_fdfs,\n",
    "                         initial_vld_data_fdfs],\n",
    "                        axis=0, sort=False, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaled_trn_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names) \n",
    "scaled_vld_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "scaled_tst_data_fdfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udfs = pd.DataFrame(mm_scaler.transform(initial_trn_data_udfs),columns=data_col_names)\n",
    "scaled_vld_data_udfs = pd.DataFrame(mm_scaler.transform(initial_vld_data_udfs),columns=data_col_names)\n",
    "scaled_tst_data_udfs = pd.DataFrame(mm_scaler.transform(initial_tst_data_udfs),columns=data_col_names)\n",
    "\n",
    "scaled_trn_data_udus = pd.DataFrame(mm_scaler.transform(initial_trn_data_udus),columns=data_col_names)\n",
    "scaled_vld_data_udus = pd.DataFrame(mm_scaler.transform(initial_vld_data_udus),columns=data_col_names)\n",
    "scaled_tst_data_udus = pd.DataFrame(mm_scaler.transform(initial_tst_data_udus),columns=data_col_names)\n",
    "'''\n",
    "trn = pd.DataFrame(mm_scaler.transform(initial_trn_data_fdfs),columns=data_col_names)\n",
    "vld = pd.DataFrame(mm_scaler.transform(initial_vld_data_fdfs),columns=data_col_names)\n",
    "tst = pd.DataFrame(mm_scaler.transform(initial_tst_data_fdfs),columns=data_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment №1\n",
    "* Input data: GMT.\n",
    "* Models: Multi-Layer Perceptron, Kolmogorov-Arnold Network.\n",
    "* Single and multiple mode predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 MLP + single mode.\n",
    "* MLP with 1 hidden layer.\n",
    "* Seperate model per each predicting depth.\n",
    "* Number neurons in hidden layer: 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['GMT_MLP_sgl_2', 'GMT_MLP_sgl_4', 'GMT_MLP_sgl_8',\n",
    "               'GMT_MLP_sgl_16', 'GMT_MLP_sgl_32', 'GMT_MLP_sgl_64', 'GMT_MLP_sgl_128',\n",
    "               'GMT_MLP_sgl_256', 'GMT_MLP_sgl_512', 'GMT_MLP_sgl_1024']\n",
    "\n",
    "l_algos=[vector_pred_NN] * 10\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(10)]\n",
    "\n",
    "l_geophysical_method = ['GMT' for i in range(10)]\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(10)]\n",
    "{'hidden_neurons':2, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True}\n",
    "l_kwargs=[{'hidden_neurons':2, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':4, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':8, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':16, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':32, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':64, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':128, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':256, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':512, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':1024, 'learning_rate': 0.001, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True}\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_1_1 = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_1_1.to_excel('full_metrics_exp1_MLP_sgl.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df_1_1 = full_df_1_1.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df_1_1.to_excel('aggr_metrics_exp1_MLP_sgl.xlsx')\n",
    "aggr_df_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 MLP + multiple mode.\n",
    "* MLP with 1 hidden layer.\n",
    "* Only one model with multiple output.\n",
    "* Number neurons in hidden layer: 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['GMT_MLP_mul_2', 'GMT_MLP_mul_4', 'GMT_MLP_mul_8',\n",
    "               'GMT_MLP_mul_16', 'GMT_MLP_mul_32', 'GMT_MLP_mul_64', 'GMT_MLP_mul_128',\n",
    "               'GMT_MLP_mul_256', 'GMT_MLP_mul_512', 'GMT_MLP_mul_1024']\n",
    "\n",
    "l_algos=[alg_keras_mlp_3_output] * 10\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(10)]\n",
    "\n",
    "l_geophysical_method = ['GMT' for i in range(10)]\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(10)]\n",
    "\n",
    "l_kwargs=[{'hidden_neurons':2, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':4, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':8, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':16, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':32, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':64, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':128, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':256, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':512, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True},\n",
    "          {'hidden_neurons':1024, 'learning_rate': 0.1, 'tol':0.001, 'n_iter_no_change':500, 'max_epochs':50000, 'rel_batch_size':0.05, 'multioutput': True}\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_1_2 = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_1_2.to_excel('full_metrics_exp1_MLP_mul.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df_1_2 = full_df_1_2.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df_1_2.to_excel('aggr_metrics_exp1_MLP_mul.xlsx')\n",
    "aggr_df_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 KAN + single mode.\n",
    "* KAN with 1 hidden layer.\n",
    "* Seperate model per each predicting depth.\n",
    "* Number neurons in hidden layer: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['GMT_KAN_sgl_1', 'GMT_KAN_sgl_2', 'GMT_KAN_sgl_3', 'GMT_KAN_sgl_4', 'GMT_KAN_sgl_5', \n",
    "               'GMT_KAN_sgl_6', 'GMT_KAN_sgl_7', 'GMT_KAN_sgl_8', 'GMT_KAN_sgl_9', 'GMT_KAN_sgl_10']\n",
    "\n",
    "l_algos=[vector_pred_KAN] * 10\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(10)]\n",
    "\n",
    "l_geophysical_method = ['GMT' for i in range(10)]\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(10)]\n",
    "\n",
    "l_kwargs=[{'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':2, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':3, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':4, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':5, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':6, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':7, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':8, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':9, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':10, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_1 = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_1.to_excel('full_metrics_exp1_KAN_sgl.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df_2_1 = full_df_2_1.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df_2_1.to_excel('aggr_metrics_exp1_KAN_sgl.xlsx')\n",
    "aggr_df_2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 KAN + multiple mode.\n",
    "* KAN with 1 hidden layer.\n",
    "* Only one model with multiple output.\n",
    "* Number neurons in hidden layer: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_algos_names=['GMT_KAN_mul_1', 'GMT_KAN_mul_2', 'GMT_KAN_mul_3', \n",
    "               'GMT_KAN_mul_4', 'GMT_KAN_mul_5', 'GMT_KAN_mul_6', 'GMT_KAN_mul_7', \n",
    "               'GMT_KAN_mul_8', 'GMT_KAN_mul_9', 'GMT_KAN_mul_10']\n",
    "\n",
    "l_algos=[vector_pred_KAN_3_output] * 10\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(10)]\n",
    "\n",
    "l_geophysical_method = ['GMT' for i in range(10)]\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(10)]\n",
    "\n",
    "l_kwargs=[{'K':3, 'hidden_neurons':1, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':2, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':3, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':4, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':5, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':6, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':7, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':8, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':9, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          {'K':3, 'hidden_neurons':10, 'learning_rate':0.1, 'tol':0.001, 'n_iter_no_change':25, 'max_epochs':500, 'lamb':0, 'multioutput': True},\n",
    "          ]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n",
    "\n",
    "num_iter=NUM_ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_2 = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_2_2.to_excel('full_metrics_exp1_KAN_mul.xlsx')\n",
    "#pd.read_excel('full_metrics.xlsx').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df_2_2 = full_df_2_2.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df_2_2.to_excel('aggr_metrics_exp1_KAN_mul.xlsx')\n",
    "aggr_df_2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 MLP from skl + single mode.\n",
    "* MLP from skl with 1 hidden layer.\n",
    "* Seperate model per each predicting depth.\n",
    "* Number neurons in hidden layer: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from algos import vector_pred_skl\n",
    "\n",
    "\n",
    "num_iter=NUM_ITER\n",
    "\n",
    "\n",
    "l_algos_names=['GMT_MLP_skl_sgl_2', 'GMT_MLP_skl_sgl_4', 'GMT_MLP_skl_sgl_8',\n",
    "               'GMT_MLP_skl_sgl_16', 'GMT_MLP_skl_sgl_32', 'GMT_MLP_skl_sgl_64', 'GMT_MLP_skl_sgl_128',\n",
    "               'GMT_MLP_skl_sgl_256', 'GMT_MLP_skl_sgl_512', 'GMT_MLP_skl_sgl_1024']\n",
    "\n",
    "l_algos=[vector_pred_skl] * 10\n",
    "\n",
    "Data = (trn, vld, tst)\n",
    "\n",
    "mult_data = [Data for i in range(10)]\n",
    "\n",
    "l_geophysical_method = ['G', 'M', 'T', 'GMT']\n",
    "\n",
    "output_parameter = ['H1_8', 'H2_8', 'H3_8']\n",
    "l_output_parameter = [output_parameter for i in range(10)]\n",
    "\n",
    "l_kwargs=[{'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[2], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[4], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[8], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[16], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[32], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[64], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[128], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[256], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[512], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "          {'class_model': MLPRegressor, 'model_kwargs': dict(hidden_layer_sizes=[1024], activation='logistic', validation_fraction=2/7, learning_rate_init=0.001, early_stopping=True, tol=0.001, n_iter_no_change=500, max_iter=50000, max_fun=50000), 'multioutput': True}, \n",
    "]\n",
    "\n",
    "l_metrics_names=['rmse_H1_8', 'rmse_H2_8', 'rmse_H3_8', \n",
    "                 'mae_H1_8', 'mae_H2_8', 'mae_H3_8', \n",
    "                 'mape_H1_8', 'mape_H2_8', 'mape_H3_8', \n",
    "                 'r2_H1_8', 'r2_H2_8', 'r2_H3_8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_3 = multi_exp(l_algos_names=l_algos_names,\n",
    "                    l_algos=l_algos,\n",
    "                    mult_data=mult_data,\n",
    "                    l_geophysical_method=l_geophysical_method,\n",
    "                    l_output_parameter=l_output_parameter,\n",
    "                    l_kwargs=l_kwargs,\n",
    "                    l_metrics_names=l_metrics_names,\n",
    "                    num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_3.to_excel('full_metrics_exp1_MLP_skl_sgl.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df_3 = full_df_2_2.groupby(['alg_name']).agg([\"mean\", \"std\"]).drop(['iter'], axis=1)\n",
    "aggr_df_3.to_excel('aggr_metrics_exp1_MLP_skl_sgl.xlsx')\n",
    "aggr_df_3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aIL8ByjQk_ZF",
    "QDmrIUSXGi4S",
    "a1xagv6ilIOY",
    "bPtIL2sBHGEr",
    "1F9IQv4404Kw",
    "RL9cZZgsCOF9",
    "SQlkq4mV2jgV",
    "rELgNsuCH-AV",
    "4anop-oMi1bP",
    "u7XdyWo2i9If",
    "q7AyylqGjDds",
    "ASErdt8-koM6",
    "gbynJqCmjDd0",
    "4nKC2GYXjDd3",
    "GTLSE0LqjDd5",
    "LniYe2gKmQU2",
    "JBY35tb-mQVF",
    "LbxePh8_mQVG",
    "sGQL1KcYmQVI",
    "Jv2nOQcDmbx4",
    "mwSMdb-DmbyA",
    "POfYqvJpmbyC",
    "mzulZ0BqmbyE",
    "b2bsNptimnn6",
    "i2kYaUXymnoA",
    "BW6pjojBmnoC",
    "f5ZNCOjImnoE",
    "P-G0m7YHmxjI",
    "STRJXlr5mxjP",
    "YK6-DC1SmxjR",
    "x0mZIr5WmxjT",
    "A_cb4zfCm8e0",
    "LAHjNKyum8e6",
    "r3V68FCLm8e7",
    "5qkzGmPBm8e9",
    "_emLc38km8e_",
    "mBkbRM6um8fB",
    "l2AfJl0Bm8fB",
    "1JvB5Vpnm8fD",
    "VnZLOfnwm8fE",
    "3Smu7Z1fm8fG",
    "ZQdqa0mzm8fG",
    "00bDDaU8m8fI",
    "wo3QxFQPm8fK",
    "LuF8EP2Qm8fM",
    "KXI9Qgpvm8fM",
    "K_rzuvZEm8fP",
    "K9skQHETm8fR",
    "p2s49zpnm8fT",
    "wrtDVW9jm8fT",
    "mtbjCRB1m8fY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
